{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from nets.utils.data import StratifiedDomainDataLoader, DomainDataset\n",
    "from nets.trainer import Trainer\n",
    "from nets.callbacks import EarlyStopping, MomentumBatchNormScheduler\n",
    "from nets.model import HEEGNet\n",
    "import nets.functionals as fn\n",
    "from copy import deepcopy\n",
    "import nets.batchnorm as bn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuration for alignment\n",
    "\n",
    "input_align, set 'True' to perform euclidian alignment in the input space\n",
    "\n",
    "domain_adaptation, set 'True' to perform the moments alignment\n",
    "\n",
    "swd_weight control the hhsw loss value, set zero to off the feature distribution alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and training configuration\n",
    "cfg = dict(\n",
    "    epochs = 100,\n",
    "    batch_size_train = 50,\n",
    "    domains_per_batch = 5,\n",
    "    validation_size = 0.2,\n",
    "    evaluation = 'inter-subject', # or 'inter-subject'\n",
    "    dtype = torch.float64,\n",
    "    training=True, \n",
    "    lr=0.001,\n",
    "    input_align= True,\n",
    "    weight_decay=1e-4,\n",
    "    swd_weight=0.01,\n",
    "    mdl_kwargs = dict( \n",
    "    bnorm_dispersion=bn.BatchNormDispersion.SCALAR,\n",
    "    domain_adaptation=True\n",
    ")\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "input the data path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the data path and load the data\n",
    "dataset='faced'\n",
    "n_classes = 9\n",
    "loading_path=''\n",
    "data, labels, subjects, sessions = fn.load_dataset(loading_path)\n",
    "\n",
    "# grouping each subject-session as a domain\n",
    "domain_labels = [f\"{sub}_{sess}\" for sub, sess in zip(subjects, sessions)]\n",
    "domain = sklearn.preprocessing.LabelEncoder().fit_transform(domain_labels)\n",
    "assert data.shape[0]==labels.shape[0]==subjects.shape[0]==sessions.shape[0]==domain.shape[0]\n",
    "domain = torch.from_numpy(domain)\n",
    "X=data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define SFUDA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfuda_offline(dataset : DomainDataset, model : HEEGNet):\n",
    "    model.eval()\n",
    "    model.domainadapt_finetune(dataset.features.to(dtype=cfg['dtype'], device=device), dataset.labels.to(device=device), dataset.domains, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load a MOABB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit and evaluat the model for all domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed=42\n",
    "torch.manual_seed(random_seed)\n",
    "records = []\n",
    "records1=[]\n",
    "# input space alignment\n",
    "if cfg['input_align']:\n",
    "    for i in domain.unique():\n",
    "        X[domain == i] = fn.euler_align(X[domain == i])\n",
    "X = torch.from_numpy(X)\n",
    "y = sklearn.preprocessing.LabelEncoder().fit_transform(labels)\n",
    "y = torch.from_numpy(y)  \n",
    "\n",
    "\n",
    "#! 10-fold CV with subjects as groups\n",
    "subject_count = len(np.unique(subjects))\n",
    "\n",
    "if subject_count <10:\n",
    "    cv_outer = sklearn.model_selection.LeaveOneGroupOut()\n",
    "else:\n",
    "    cv_outer = sklearn.model_selection.GroupKFold(n_splits=10)\n",
    "cv_outer_group = subjects\n",
    "#! train/validation split stratified across domains and labels\n",
    "cv_inner_group = [f\"{d.item()}_{l}\" for d, l in zip(domain, y)]\n",
    "cv_inner_group = sklearn.preprocessing.LabelEncoder().fit_transform(cv_inner_group)\n",
    "# add datadependen model kwargs\n",
    "mdl_kwargs = deepcopy(cfg['mdl_kwargs'])\n",
    "mdl_kwargs['num_classes'] = n_classes\n",
    "mdl_kwargs['num_electrodes'] = X.shape[1]\n",
    "mdl_kwargs['chunk_size'] = X.shape[2]\n",
    "mdl_kwargs['domains'] = domain.unique()\n",
    "for ix_fold, (fit, test) in enumerate(cv_outer.split(X, y, cv_outer_group)):\n",
    "\n",
    "    # split fitting data into train and validation \n",
    "    cv_inner = sklearn.model_selection.StratifiedShuffleSplit(n_splits=1, test_size=cfg['validation_size'])\n",
    "    train, val = next(cv_inner.split(X[fit], y[fit], cv_inner_group[fit]))\n",
    "\n",
    "    # adjust number of \n",
    "    du = domain[fit][train].unique()\n",
    "    if cfg['domains_per_batch'] > len(du):\n",
    "        domains_per_batch = len(du)\n",
    "    else:\n",
    "        domains_per_batch = cfg['domains_per_batch']\n",
    "\n",
    "    # split entire dataset into train/validation/test\n",
    "    ds_train = DomainDataset(X[fit][train], y[fit][train], domain[fit][train])\n",
    "    ds_val = DomainDataset(X[fit][val], y[fit][val], domain[fit][val])\n",
    "    \n",
    "\n",
    "    # create dataloaders\n",
    "    # for training use specific loader/sampler so taht \n",
    "    # batches contain a specific number of domains with equal observations per domain\n",
    "    # and stratified labels\n",
    "    loader_train = StratifiedDomainDataLoader(ds_train, cfg['batch_size_train'], domains_per_batch=domains_per_batch, shuffle=True, drop_last = False)\n",
    "    loader_val = torch.utils.data.DataLoader(ds_val, batch_size=len(ds_val))\n",
    "    test_domain=domain[test].unique()\n",
    "\n",
    "    # create the model and training configuration\n",
    "    model = HEEGNet(device=device,dtype=cfg['dtype'],**mdl_kwargs).to(device=device, dtype=cfg['dtype'])\n",
    "    es = EarlyStopping(metric='val_loss', higher_is_better=False, patience=20, verbose=False)\n",
    "    bn_sched = MomentumBatchNormScheduler(\n",
    "        epochs=cfg['epochs']-10,\n",
    "        bs0=cfg['batch_size_train'],\n",
    "        bs=cfg['batch_size_train']/cfg['domains_per_batch'], \n",
    "        tau0=0.85\n",
    "    )\n",
    "\n",
    "    # create the trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs= cfg['epochs'],\n",
    "        min_epochs= 70,\n",
    "        callbacks=[es,bn_sched],\n",
    "        loss=torch.nn.CrossEntropyLoss(),\n",
    "        device=device, \n",
    "        dtype=torch.float64,\n",
    "        swd_weight=cfg['swd_weight'],\n",
    "        lr=cfg['lr'],\n",
    "\n",
    "    )\n",
    "    # fit the model\n",
    "    trainer.fit(model, train_dataloader=loader_train, val_dataloader=loader_val)\n",
    "    print(f'ES best epoch={es.best_epoch}')\n",
    "    sfuda_offline_net= deepcopy(model)\n",
    "\n",
    "    # evaluation\n",
    "    test_domain=domain[test].unique()\n",
    "    for test_domain in test_domain:\n",
    "        fold=ix_fold\n",
    "        print(f\"Fold:{fold}, test domain: {test_domain}\")    \n",
    "        ds_test = DomainDataset(X[test][domain[test] == test_domain], y[test][domain[test] == test_domain], domain[test][domain[test] == test_domain])\n",
    "        loader_test = torch.utils.data.DataLoader(ds_test, batch_size=len(ds_test))\n",
    "        sfuda_offline(ds_test, sfuda_offline_net)\n",
    "        res = trainer.test(sfuda_offline_net, dataloader=loader_test)\n",
    "        res2 = res\n",
    "        print(f\"HEEGNet, Test results: {res2}\")\n",
    "        records.append(dict(dataset=dataset,fold=fold,domain=test_domain, **res))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf = pd.DataFrame(records)\n",
    "resdf.groupby(['dataset']).agg(['mean', 'std']).round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
